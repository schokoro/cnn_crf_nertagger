{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "NER_tagger.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schokoro/cnn_crf_nertagger/blob/dev/NER_tagger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_aAUmhzgFqt",
        "colab_type": "text"
      },
      "source": [
        "# Свёрточные нейросети и POS-теггинг\n",
        "\n",
        "POS-теггинг - определение частей речи (снятие частеречной неоднозначности)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVSH61-2h4l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device == 'cpu':\n",
        "    print('cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcYhczUAh6Ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVzEU3MPb8nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf cnn_crf_nertagger/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BZw4sQ4gFrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone -b dev https://github.com/schokoro/cnn_crf_nertagger.git > /dev/null\n",
        "!pip install allennlp > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:34.549739Z",
          "start_time": "2019-10-29T19:49:32.179692Z"
        },
        "id": "ol61j2fHgFsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from allennlp.data.dataset_readers.conll2003 import Conll2003DatasetReader\n",
        "from allennlp.common.util import ensure_list\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from pdb import set_trace\n",
        "from gc import collect\n",
        "\n",
        "import cnn_crf_nertagger\n",
        "from cnn_crf_nertagger.modules.modules import NERTaggerModel\n",
        "from cnn_crf_nertagger.utils.pipeline import train_eval_loop, predict_with_model\n",
        "from cnn_crf_nertagger.utils.prepare import tag_corpus_to_tensor\n",
        "\n",
        "# init_random_seed()\n",
        "\n",
        "torch.backends.cudnn.deterministic=False "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inP4QwcDgFs3",
        "colab_type": "text"
      },
      "source": [
        "## Загрузка корпусов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:56.525561Z",
          "start_time": "2019-10-29T19:49:37.315213Z"
        },
        "id": "uo0ZTJ1FgFti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_train = '/content/drive/My Drive/NER_tagger/data/eng.train'\n",
        "path_valid = '/content/drive/My Drive/NER_tagger/data/eng.testa'\n",
        "path_test = '/content/drive/My Drive/NER_tagger/data/eng.testb'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6AABrk05iiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "conll_reader = Conll2003DatasetReader()\n",
        "train_conll = ensure_list(conll_reader.read(path_train))\n",
        "valid_conll = ensure_list(conll_reader.read(path_valid))\n",
        "test_conll = ensure_list(conll_reader.read(path_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCYr630b8O5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_conll = train_conll + valid_conll + test_conll\n",
        "len(all_conll), len(train_conll), len(valid_conll), len(test_conll)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "662ybzBM8hxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joAECv5_8htA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags = set()\n",
        "tokens = set()\n",
        "\n",
        "max_sent_len = 0\n",
        "for instance in all_conll[: ]:\n",
        "    if len(instance['tokens']) >  max_sent_len:\n",
        "        max_sent_len = len(instance['tokens'])\n",
        "    tags.update(instance['tags'])\n",
        "    tokens.update(instance['tokens'])\n",
        "    \n",
        "max_sent_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaDuu3t_8hqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_token_len = max([len(token.text) for token in tokens])\n",
        "max_token_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw8rY17i8hnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = set()\n",
        "for token in tokens:\n",
        "    chars.update(token.text)\n",
        "    \n",
        "len(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.524125Z",
          "start_time": "2019-10-29T19:49:58.125577Z"
        },
        "id": "WzDDott3gFul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag2id = {tag: num for num, tag in enumerate(['<NOTAG>'] + list(tags))}\n",
        "char2id = {char: num+1 for num, char in enumerate(chars)}\n",
        "id2char = {item[1]: item[0] for item in char2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO0uquKu87yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "train_inputs, train_targets = tag_corpus_to_tensor(train_conll, char2id, tag2id, max_sent_len, max_token_len)\n",
        "valid_inputs, valid_targets = tag_corpus_to_tensor(valid_conll, char2id, tag2id, max_sent_len, max_token_len)\n",
        "test_inputs, test_targets = tag_corpus_to_tensor(test_conll, char2id, tag2id, max_sent_len, max_token_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.752672Z",
          "start_time": "2019-10-29T19:49:58.526431Z"
        },
        "id": "K_03GuyhgFur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(train_inputs, train_targets)\n",
        "valid_dataset = TensorDataset(valid_inputs, valid_targets)\n",
        "test_dataset = TensorDataset(test_inputs, test_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5k4Z4b6craL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models_path = '/content/drive/My Drive/NER_tagger/models/char_token_level_ner.pth'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfRjCwqZu4BW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    del sentence_level_model    \n",
        "except:\n",
        "    print('no model')\n",
        "finally:\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.326925Z",
          "start_time": "2019-10-29T19:46:50.310Z"
        },
        "id": "jj9cwrRBgFwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "sentence_level_model = NERTaggerModel(len(char2id), len(tag2id), tag2id, embedding_size=64,\n",
        "                                              single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.1, dilation=[1,1,2]),\n",
        "                                              context_backbone_kwargs=dict(layers_n=4, kernel_size=3, dropout=0.1, dilation=[1,1,2,3]))\n",
        "print('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model.parameters()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luP8K58IIlw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_level_model.load_state_dict(torch.load(models_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.327888Z",
          "start_time": "2019-10-29T19:46:50.737Z"
        },
        "scrolled": false,
        "id": "4aa02MY9gFwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(best_val_loss,\n",
        " best_sentence_level_model) = train_eval_loop(sentence_level_model,\n",
        "                                              train_dataset,\n",
        "                                              valid_dataset,\n",
        "                                              tag2id,\n",
        "                                              lr=5e-3,\n",
        "                                              epoch_n=200,\n",
        "                                              batch_size=32,\n",
        "                                              device=device,\n",
        "                                              early_stopping_patience=8,\n",
        "                                              l2_reg_alpha = 1e-7,\n",
        "                                              max_batches_per_epoch_train=200,\n",
        "                                              max_batches_per_epoch_val=200,\n",
        "                                              lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                                                  optim, patience=2,\n",
        "                                                  factor=0.1,\n",
        "                                                  threshold=1e-4,\n",
        "                                                  verbose=True),\n",
        "                                             verbose_batch=False)\n",
        " \n",
        "torch.save(best_sentence_level_model.state_dict(), models_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:16.564926Z",
          "start_time": "2019-08-29T13:56:16.544481Z"
        },
        "id": "j6_Z8S3SgFwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab, добавьте в начало пути /content/stepik-dl-nlp\n",
        "sentence_level_model.load_state_dict(torch.load(models_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.092139Z",
          "start_time": "2019-08-29T13:56:16.567242Z"
        },
        "id": "GP3XEV_egFwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pred = predict_with_model(sentence_level_model, train_dataset)\n",
        "train_pred.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aNr47CYdSFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# train_loss = F.cross_entropy(torch.tensor(train_pred),\n",
        "                            #  torch.tensor(train_targets))\n",
        "# print('Среднее значение функции потерь на обучении', float(train_loss))\n",
        "UNIQUE_TAGS =[key for key in tag2id.keys()]\n",
        "# UNIQUE_TAGS.remove('<NOTAG>')\n",
        "# train_pred = train_pred.argmax(1)\n",
        "# mask = (train_inputs[:, :, 1] != 0)\n",
        "# train_pred = -sentence_level_model.crf(train_pred.permute(0, 2, 1), train_targets, mask)\n",
        "\n",
        "print(train_pred.shape)\n",
        "print(classification_report(train_targets.view(-1), train_pred.reshape(-1), target_names=UNIQUE_TAGS))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oudfd_50tsmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in range(9):\n",
        "    print((train_pred.argmax(1).reshape(-1) == n).sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAh6GumkdR4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# valid_pred = predict_with_model(sentence_level_model, valid_dataset)\n",
        "# # valid_loss = F.cross_entropy(torch.tensor(valid_pred),\n",
        "# #                             torch.tensor(valid_targets))\n",
        "# # print('Среднее значение функции потерь на валидации', float(valid_loss))\n",
        "\n",
        "# print(classification_report(valid_targets.view(-1), valid_pred.reshape(-1), target_names=UNIQUE_TAGS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8GW9E-eUpnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in range(9):\n",
        "    print((valid_pred.argmax(1).reshape(-1) == n).sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIC16ECm_58u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = predict_with_model(sentence_level_model, test_dataset)\n",
        "# test_loss = F.cross_entropy(torch.tensor(test_pred),\n",
        "#                             torch.tensor(test_targets))\n",
        "# print('Среднее значение функции потерь на тесте', float(test_loss))\n",
        "print(classification_report(test_targets.view(-1), test_pred.reshape(-1), target_names=UNIQUE_TAGS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biKJ47GKMDEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in range(9):\n",
        "    print((test_pred.argmax(1).reshape(-1) == n).sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tZ3TbhngFxV",
        "colab_type": "text"
      },
      "source": [
        "## Применение теггера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.105418Z",
          "start_time": "2019-08-29T13:56:42.093744Z"
        },
        "id": "gM1646Q7gFxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sentence_level_pos_tagger = POSTagger(sentence_level_model, char2id, UNIQUE_TAGS, max_sent_len, max_token_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBORSeRvdITg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnZHW0OKbcLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.125540Z",
          "start_time": "2019-08-29T13:56:42.106771Z"
        },
        "id": "JHOY3BpZgFxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentences = [\n",
        "    'Mr Trump said Mr Linick no longer had his full confidence and that he would be removed in 30 days.',\n",
        "    'Mr Linick had begun investigating Secretary of State Mike Pompeo for suspected abuse of office, reports say.',\n",
        "    'Democrats say Mr Trump is retaliating against public servants who want to hold his administration to account.',\n",
        "    'Donald Trump, who is campaigning for re-election in November, has stepped up his attacks on China in recent weeks, blaming it for the spread of Covid-19.'\n",
        "]\n",
        "# test_sentences_tokenized = tokenize_corpus(test_sentences, min_token_size=1)\n",
        "test_sentences_tokenized = [[token.text for token in nlp.tokenizer(sent) ] for sent in test_sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xsu6dl4bKSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sent in test_sentences_tokenized:\n",
        "    print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.168810Z",
          "start_time": "2019-08-29T13:56:42.149698Z"
        },
        "id": "vbozpJwYgFxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sent_tokens, sent_tags in zip(test_sentences_tokenized, sentence_level_pos_tagger(test_sentences)):\n",
        "    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUJvKJ0KJaGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}